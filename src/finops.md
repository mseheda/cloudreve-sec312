# Самарі

Рішення поєднує надлишковість (дві AZ, Multi-AZ RDS, резервні копії) і автоматичне масштабування (ASG), а також FinOps-практики (таґування, бюджети/алерти, резервування інстансів, оптимізація сховища). Загальна вартість інфраструктури прогнозується ≲100 USD/місяць. Основні драйвери витрат — обчислювальні ресурси (EC2, ASG), NAT-шлюзи, ALB, RDS-інстанс і мережеві витрати (передача даних). У звіті проаналізовано альтернативи (ECS/Fargate, Lambda, Aurora) і наведено план оптимізації на 30/60/90 днів.

---

# Вихідні вимоги (з ТЗ)

- **Навантаження:** до 100 RPS для двох шарів (фронтенд/бекенд).
- **Оточення:** одне продакшен-середовище, одна команда розробників.
- **Бюджет:** не більше 100 USD/місяць.
- **Компоненти:** дві ALB (публічна для інтернету і внутрішня для бекенду), дві групи автошкалювання (ASG) — для фронтенду і бекенду, EC2-інстанси, RDS MySQL (Multi-AZ), S3-бакети (дані, резервні копії), NAT Gateway, IAM, Security Groups, маршрути, VPC у 2 AZ.
- **Безпека:** сегментація (публічні/приватні підмережі), IAM з мінімальними правами, шифрування S3 і RDS, TLS для зв’язку, регулярні бекапи.
- **Оберігання й доступність:** least privilege, інфраструктура в кількох AZ, резервні копії/реплікація, план відновлення RTO/RPO.
- **FinOps:** моніторинг витрат, бюджети й алерти (AWS Budgets, Cost Explorer), SLO для доступності та продуктивності.
- **Управління конфігурацією:** Infra as Code — Terraform з best practices (таґування, автоматизація, versioning, lifecycle).

---

# Опис обраної інфраструктури

Вибрано тришарову архітектуру для безпеки та масштабованості. VPC охоплює дві AZ, у кожній — публічні й приватні підмережі. У публічних підмережах розміщено зовнішній ALB, що балансуватиме трафік до автошкалювання фронтенд-EC2.

Приватні підмережі містять EC2-інстанси в ASG для бекенду, за ними — RDS MySQL із Multi-AZ реплікацією для забезпечення високої доступності. Вихід у інтернет із приватних підмереж проходить через NAT Gateway в кожній AZ (для виходу бекенду/бекапів), а внутрішня ALB (inside-LB) у приватних підмережах скеровує трафік від фронтенду до бекенду.

Резервні копії БД та архівні дані зберігаються в S3-бакетах (окремо під дані і під бекапи) з увімкненим versioning і життєвим циклом на архівацію у Glacier. Всі S3-об’єкти шифруються на рівні сервісу. VPN та TLS забезпечують захищений зв’язок, набір Security Group обмежує доступ за принципом мінімального доступу. IAM-ролі призначені EC2 і сервісам для необхідних операцій (наприклад, збереження бекапів у S3). Інфраструктура описана в Terraform з налаштуванням autoscaling, моніторингом (Amazon CloudWatch) і процедурами бекапів (AWS Backup).

Це забезпечує вимоги до доступності та стійкості: Multi-AZ RDS відповідає продакшн-SLO за RPO/RTO (AWS рекомендовано Multi-AZ для критичних БД, незважаючи на додаткові витрати). Автомасштабування EC2 дозволяє підтримувати продуктивність до 100 RPS при пікових навантаженнях. VPC із двома AZ і двома ALB гарантує безперервний сервіс навіть за виходу однієї AZ з ладу. Інфраструктура у коді (Terraform) виключає людський фактор, прискорює відновлення й крос-регіональне відновлення за необхідності.

---

# Фінансове обґрунтування (FinOps)

Ми аналізували unit economics та TCO сервісів, щоб оптимально вписатися у бюджет. Основні драйвери витрат:

## NAT Gateway
Наразі в архітектурі — 2 NAT (по одному на AZ). AWS стягує близько $43/місяць за кожен NAT Gateway плюс $0.059 за ГБ трафіку. Для двох NAT це ≈$86 базово, не рахуючи передачі даних. За 1 ТБ трафіку в місяць один NAT коштуватиме ~$103 plus $43 = $146. Тому NAT Gateway є критичним драйвером витрат (до 30–40%).

Альтернативно можна розглянути NAT Instance (соборується на EC2), але стандартний AWS AMI для NAT застарілий й небезпечний. За потреби можна самостійно розгорнути сучасний NAT на EC2 з Graviton (як описано у відкритому рішенні fck-nat). Це знижує базові витрати із ~$42 до ~$3.8/місяць на екземпляр при низькому навантаженні, але вимагає самостійного моніторингу і конфігурації failover.

## Обчислювальні ресурси (EC2/ASG)
Використовуємо невеликі multi-AZ EC2 (наприклад, T3.nano–T3.micro), автоскейлінг та балансувальники. Такі інстанси коштують від $0.005–0.01/год (≈$3–7/місяць) кожен. Дві ASG по 2 інстанси (по одному на AZ) — загалом ≈$30/місяць.

Масштабування за необхідності та зупинка непотрібних інстансів уночі (не продакшен) дають додаткову економію. За умови стабільного використання рекомендовані Savings Plans (commitment на рік), які дають до 50% знижку. Зрештою, EC2/ASG будуть іншими великими витратами (≈25–35%).

## RDS MySQL (Multi-AZ)
Інстанс (наприклад, db.t3.small) в on-demand може коштувати ~$15/місяць без реплікації. З Multi-AZ це ×2 (~$30), плюс сховище (20 GB gp2 ≈$2) — загалом близько $32. Trusted Advisor рекомендує Multi-AZ у продакшн для HA (за це потрібно доплатити).

Можлива оптимізація: перехід на Aurora Serverless або General Purpose Aurora, але зазвичай Aurora дорожча та складніша у налаштуванні. У нашому малому навантаженні звичайний RDS дешевший за Aurora. З часом також можливі Reserved Instances за нижчою ціною. RDS зараз — приблизно 20–30% витрат.

## Application Load Balancer
Кожен ALB коштує ~$0.0252/год ($18.4/місяць) плюс ~$0.008/LCU-год (≈$6 при помірному навантаженні). З двома ALB це ~($18.4+6)*2 ≈ $50/місяць. ALB — відносно невелика стаття витрат (~10–15%), але вона забезпечує безперебійну маршрутизацію та TLS-термінацію.

AWS Free Tier покриває 750 годин ALB і 15 LCU/місяць для нових акаунтів, що на початкових стадіях може трохи знизити витрати.

## S3 і сховище
Стандартне зберігання S3 Standard — близько $0.023/ГБ-місяць. Використовуємо життєвий цикл: часто незатребувані дані переводимо до S3 IA та Glacier. Наприклад, логи й бекапи старше 30 днів йдуть на Glacier (∼$0.004/ГБ-місяць). Це знижує TCO зберігання даних.

Крім того, увімкнено версіювання і (за необхідності) CRR/CloudWatch для RTO/RPO. Як радить FinOps, ми застосовуємо Data Lifecycle Management (перехід у архів, видалення старих артефактів). S3 зараз — невелика стаття витрат (≤5%), а Glacier майже безкоштовний для довготривалого зберігання.

## Мережеві витрати (Egress)
Передача даних з AWS коштує від ~$0.09/ГБ. Якщо фронтенд активно виходить в інтернет, це може стати значним. Оптимізація: використання CDN (Amazon CloudFront) для статичних даних і кешування результатів, обмеження зайвих виходів. Як рекомендує FinOps, «optimize network egress by caching or regional placement»[1]. При помірному трафіку витрати на egress мають бути мінімальні, їх можна контролювати через AWS Cost Explorer і встановлені budget alerts.

## Висновок щодо витрат
Загалом, ключові драйвери витрат — NAT Gateway (≈$86+/міс), EC2/ASG (≈$30–40/міс), RDS Multi-AZ (≈$30/міс) і ALB (≈$50/міс). Щоб утримати бюджет, ми застосовуємо autoscaling (запускаємо лише потрібні ресурси) і ранжуємо оптимізації (rightsizing, commit-покупки). Зокрема, плануємо придбати 1-річні Savings Plans для EC2/RDS, що може знизити рахунок удесятеро.

---

# Альтернативи та чому від них відмовились

## Контейнеризація (ECS/EKS/Fargate)
Розглядали запуск фронтенду і бекенду у контейнерах AWS ECS (на EC2 чи Fargate). Це дозволило б гнучкіше масштабування і простіше деплой, але коштує дорожче. Наприклад, за підрахунками AWS, два t3.medium (загалом ≈$60/міс) можуть обслуговувати 5 мікросервісів за $70/міс, тоді як Fargate (0.5vCPU+1GB на сервіс) — близько $90/міс за ті ж 5 сервісів. По-суті, Fargate виявляється на 20–30% дорожчим, ніж EC2-кластер.

Для нашого невисокого навантаження ця різниця виходить за рамки бюджету, а складність кластер-менеджменту (розгортання VPC, ASG тощо) непотрібна, адже EC2 з autoscaling уже відповідає вимогам. Автомасштабування EC2 під наші випадки більш економне завдяки використанню Spot-інстансів або Savings Plan. Переваги контейнерів (portability, простіший rollout) при обмеженому бюджеті не переважують витрат.

## Безсерверні функції (AWS Lambda)
Lambda при малому навантаженні дешевша за EC2 (напр., 10k запитів/день на Lambda ≈$0.3/місяць). Проте зі 100 RPS (≈8.6 млн запитів/день) Lambda стане дуже дорогою через плату за кожне виконання, крім обмежень часу виконання та холодних стартів.

AWS оцінює: щоб мати $86/міс на m4.large, Lambda довелося б обробляти понад 2–80 запитів/сек кожен (залежно від часу виконання). У нашому випадку застосування Lambda привело б до непередбачених витрат і архітектурних ускладнень (поділ коду на функції, API Gateway, обробка помилок). Як зазначають AWS FinOps-архітектори, для «steady, high-volume traffic» Lambda часто дорожча за контейнери/EC2. Отже, Lambda підходить для періодичних чи подієвих задач (dev/тест), але не для даного стабільного навантаження.

## СУБД (Aurora Serverless)
Альтернативою RDS MySQL був Aurora Serverless або Aurora provisioned. Aurora дає високу продуктивність та автоскейлінг сховища (до 128 TiB), що при динамічних навантаженнях знижує ризик I/O-вузького місця. Але за такими можливостями треба доплачувати: Aurora дешевше витратна при активному I/O (платиш за запити) і під час піків зростають витрати.

Для нашого невеликого проєкту RDS простіший і надійніший (MySQL добре знайомий розробникам). Вибір Aurora Serverless відтермінували: якщо в подальшому зросте навантаження й бюджет дозволить, можлива міграція. Наразі зупинилися на звичайному RDS із використанням snapshot і AWS Backup для бекапів (перевага — нижча вартість початкової конфігурації і відсутність платних I/O на малому навантаженні).

---

# Ризики та компроміси

- **NAT Gateway vs. NAT Instance:** NAT Gateway забезпечує простоту та високу доступність, але коштує дорого (~$43/шт). NAT Instance на EC2 була б дешевшою, проте стандартний AWS NAT AMI застарілий і небезпечний. Ми пішли на компроміс: спочатку використали NAT Gateway для простоти (вміщаємося у бюджет із низьким трафіком), а згодом у беклог оптимізації можлива заміна на сучасний NAT (fck-nat на Graviton) для економії.
- **Multi-AZ vs. вартість:** вибір Multi-AZ RDS і двох ALB/AZ дає високу стійкість, але збільшує TCO. Якщо бюджет надто тисне, можна відмовитись від частини надлишковості (наприклад, Single-AZ RDS чи один ALB), але це підвищить ризик простоїв і збільшить RTO. Ми обрали надійність як пріоритет.
- **Безпека vs. витрати:** використання AWS-менеджованих сервісів (ALB, RDS, Backup) підвищує витрати у порівнянні з самостійним (Nginx+EC2, MySQL на EC2), але дає покращену безпеку та зручність патчингу. Цей вибір зроблено на користь стандартів безпеки й менших операційних ризиків.
- **Lambda cold starts та обмеження:** Lambda мала б ризик холодних стартів та обмеження 15 хв для довготривалих процесів. Ми відмовились від неї через це (критичні бекенд-запити не повинні затримуватись).
- **Автоскейлінг:** правильно налаштоване автоскейлінг знижує витрати (працюють тільки потрібні інстанси), але якщо threshold-и виставлені невірно, можливі недовантаження або перевитрати. Будемо моніторити метрики (CPU, RPS) та підтверджувати настройки.
- **Керування витратами:** існує ризик «загублених» ресурсів (непотрібні EBS, незашифровані S3, невикористані ELB). Щоб уникнути цього, у Terraform і CI ставимо вимоги про теги та шифрування. AWS Budgets з фіксованими лімітами, аномалії в споживанні будуть сигналізувати.
- **Обмеження бюджету:** $100/міс — суворий ліміт. Потрібно оптимізувати бекапи та розміри інстансів. План на 90 днів включає неперервний перегляд витрат і ведення optimization backlog.

---

# План оптимізації (30/60/90 днів)

## 30 днів
Налаштувати AWS Cost Explorer і AWS Budgets з порогами (наприклад, $80/міс), щоб отримувати сповіщення при наближенні ліміту. Реалізувати базове маркування (Project, Environment, Owner) ресурсів у Terraform (для showback/chargeback). Провести базову панельнізацію (dashboard) у CloudWatch/QuickSight, розрахувати очікувані витрати на одиницю роботи (RPS, хостинг клієнта) — формуємо unit economics (витрату на 1 клієнт/запит). Налагодити регулярні зустрічі для перегляду KPI (cost per customer, прогноз vs фактичні витрати).

## 60 днів
Проаналізувати фактичну завантаженість (CPU, мережа, RPS). Здійснити rightsizing інстансів EC2/RDS: зменшити розміри чи кількість за спокійних періодів, налаштувати scheduled scaling. Закупити Savings Plans/Reserved Instances: наприклад, 1-річний план для EC2/RDS ~50–60% від вартості on-demand. Запустити тестову заміну NAT Gateway на NAT Instance (fck-nat) у одній AZ для оцінки економії ~90%. Розглянути використання EFS чи S3 для спільних даних з lifecycle, якщо є потреба в файлообміні (альтернатива — що може зменшити egress). У S3 реалізувати правила переведення в Glacier після 30 днів. Оформити optimization backlog: список завдань (rightsizing, видалення зайвого, аналітика витрат) з оцінкою економії.

## 90 днів
Провести QA фінансової моделі, порівнюючи фактичні витрати з прогнозом. Підготувати наступні оптимізації: розглянути перехід на більш дешеву зону чи інший регіон, якщо є різниця в ціні. Закінчити тест заміни NAT і вирішити про повну міграцію, якщо знижено витрати та збережено високу доступність (використовуючи два NAT Instance з автоскейлінгом). Автоматизувати ще більше: можливе застосування Instance Scheduler для dev/stage (якщо такі є). Продовжити поліпшення контролю: впровадити IAM (наприклад, Service Control Policies) для обмеження створення дорогих ресурсів, побудувати процес FinOps Review (раз на квартал аналіз витрат з фінансами/розробниками). Усі кроки регулярно перевіряти та коригувати (циклічне FinOps).

---

# Драйвери збереження коштів

Акцентовано на rightsizing інстансів і резервних планах (залишити лише продуктивні інстанси, використовувати Savings Plans), а також на зменшенні мережевих витрат (перенесення статичних даних на CDN чи кеш). Такий підхід перекриває головні рекомендації FinOps: прогнозування бюджету, аномальне оповіщення та управління технічним боргом оптимізації (optimization backlog).

---

# Загальний висновок

Обране рішення забезпечує баланс між вартістю, масштабованістю і ризиком: EC2/ASG + RDS дають високу керованість і стабільність, ALB/2AZ — надійну доступність, IAM/S3/TLS — вимоги безпеки, а FinOps-підхід контролює витрати. При потребі архітектура може бути перероблена (наприклад, на контейнерну) в майбутньому з урахуванням зростання навантаження і бюджету, але наразі вона є оптимальною для даного проєкту.
